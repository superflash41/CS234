# Quick check!
In a Markov Decision Process, a large discount factor $\gamma$ means that short term rewards are much more influential than long term rewards.

- [ ] True
- [x] False
# Markov Reward Process
Last time we saw that a MRP is a Markov chain with rewards that vary depending on the state.
## Reward & Value Function
**Horizon** refers to the number of **time steps over which the agent operates** in an environment.

A horizon can include a fixed number of steps or it can continue indefinitely.

A horizon allows for different planning strategies and helps determine **how far into the future the agent should consider rewards**.

The accumulated reward an agent receives from time step $t$ onward is called **return**.

In other words, a return $G_t$ can be calculated as the sum of all rewards from the current time step $t$ until the horizon $H$:
$$ G_t = r_t+\gamma * r_{t+1}+{\gamma}^2 * r_{t+2}+...+{\gamma}^{H-1}*r_{t+H-1}$$
Useful as it shows the **cumulative reward from a given point in time**, helping agents evaluate the **long-term benefit**.